<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>WebGPU Video Processor</title>
  <link rel="icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>ðŸŽ¥</text></svg>" />
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 20px;
      background-color: #f5f5f5;
    }

    .container {
      max-width: 1000px;
      margin: 0 auto;
    }

    .control-panel {
      background: white;
      padding: 20px;
      border-radius: 8px;
      margin-bottom: 20px;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }

    .video-container {
      background: white;
      padding: 20px;
      border-radius: 8px;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
      display: flex;
      gap: 20px;
      flex-wrap: wrap;
    }

    .video-section {
      flex: 1;
      min-width: 300px;
    }

    .video-section h3 {
      margin-top: 0;
      color: #333;
    }

    video {
      width: 100%;
      max-width: 640px;
      border: 2px solid #ddd;
      border-radius: 4px;
    }

    button {
      padding: 10px 20px;
      font-size: 16px;
      border: none;
      border-radius: 4px;
      cursor: pointer;
      margin-right: 10px;
      margin-bottom: 10px;
    }

    .start-btn {
      background-color: #4CAF50;
      color: white;
    }

    .stop-btn {
      background-color: #f44336;
      color: white;
    }

    .start-btn:disabled, .stop-btn:disabled {
      background-color: #ccc;
      cursor: not-allowed;
    }

    .checkbox-container {
      margin: 10px 0;
    }

    .checkbox-container input[type="checkbox"] {
      margin-right: 8px;
    }

    .status {
      padding: 10px;
      border-radius: 4px;
      margin: 10px 0;
      font-weight: bold;
    }

    .status.info {
      background-color: #d1ecf1;
      color: #0c5460;
    }

    .status.error {
      background-color: #f8d7da;
      color: #721c24;
    }

    .status.success {
      background-color: #d4edda;
      color: #155724;
    }

    .stats {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 10px;
      margin-top: 10px;
    }

    .stat-item {
      background: #f8f9fa;
      padding: 10px;
      border-radius: 4px;
      border-left: 4px solid #007bff;
    }

    .stat-label {
      font-size: 12px;
      color: #666;
      text-transform: uppercase;
    }

    .stat-value {
      font-size: 18px;
      font-weight: bold;
      color: #333;
    }
  </style>
</head>

<body>
  <div class="container">
    <h1>WebGPU Video Processor</h1>
    <p>Demonstrates MediaStreamTrackProcessor â†’ WebGPU/WebGL2 â†’ MediaStreamTrackGenerator pipeline with optional GPU readback and encoding via WebCodecs or WebRTC.</p>

    <div class="control-panel">
      <h2>Controls</h2>
      
      <button id="startBtn" class="start-btn">Start Camera</button>
      <button id="stopBtn" class="stop-btn" disabled>Stop</button>
      
      <div class="checkbox-container">
        <label>
          <input type="checkbox" id="enableReadback" />
          Enable GPU Readback (scales down to 255Ã—144 and reads back texture data - performance impact)
        </label>
      </div>
      
      <div class="checkbox-container">
        <label>
          <input type="checkbox" id="enableEncoding" />
          Enable WebCodecs H.264 Encoding (720p30fps)
        </label>
      </div>
      
      <div class="checkbox-container">
        <label>
          <input type="checkbox" id="enableDecoding" />
          Enable WebCodecs H.264 Decoding (decode encoded stream back to video for quality comparison)
        </label>
      </div>
      
      <div class="checkbox-container">
        <label>
          <input type="checkbox" id="enableWebRTC" />
          Enable WebRTC H.264 Pipeline (loopback peer connection - alternative to WebCodecs)
        </label>
      </div>
      
      <div class="checkbox-container">
        <label>
          <input type="checkbox" id="useWebGL2" />
          Use WebGL2 Implementation (instead of WebGPU for processing and readback)
        </label>
      </div>
      
      <div class="checkbox-container">
        <label>
          <input type="checkbox" id="showInputVideo" />
          Show Original Input Video (camera feed)
        </label>
      </div>
      


      <div id="status" class="status info">Click "Start Camera" to begin</div>

      <div class="stats">
        <div class="stat-item">
          <div class="stat-label">Processing FPS</div>
          <div class="stat-value" id="processingFps">--</div>
        </div>
        <div class="stat-item">
          <div class="stat-label">Readback FPS</div>
          <div class="stat-value" id="readbackFps">--</div>
        </div>
        <div class="stat-item">
          <div class="stat-label">Encoding FPS</div>
          <div class="stat-value" id="encodingFps">--</div>
        </div>
        <div class="stat-item">
          <div class="stat-label">Decoding FPS</div>
          <div class="stat-value" id="decodingFps">--</div>
        </div>
        <div class="stat-item">
          <div class="stat-label">WebRTC FPS</div>
          <div class="stat-value" id="webrtcFps">--</div>
        </div>
        <div class="stat-item">
          <div class="stat-label">Input Resolution</div>
          <div class="stat-value" id="inputResolution">--</div>
        </div>
        <div class="stat-item">
          <div class="stat-label">Output Resolution</div>
          <div class="stat-value" id="outputResolution">--</div>
        </div>
        <div class="stat-item">
          <div class="stat-label">GPU Backend</div>
          <div class="stat-value" id="gpuBackend">--</div>
        </div>
        <div class="stat-item">
          <div class="stat-label">Encoding Queue</div>
          <div class="stat-value" id="encodingQueue">--</div>
        </div>
        <div class="stat-item">
          <div class="stat-label">Decoding Queue</div>
          <div class="stat-value" id="decodingQueue">--</div>
        </div>
      </div>
    </div>

    <div class="video-container">
      <div class="video-section" id="inputVideoSection" style="display: none;">
        <h3>Input Video (Camera)</h3>
        <video id="inputVideo" autoplay playsinline muted></video>
      </div>
      
      <div class="video-section">
        <h3>Output Video (WebGPU Processed)</h3>
        <video id="outputVideo" autoplay playsinline muted></video>
      </div>
      
      <div class="video-section" id="decodedVideoSection" style="display: none;">
        <h3>Decoded Video (H.264 Encode/Decode)</h3>
        <video id="decodedVideo" autoplay playsinline muted></video>
      </div>
      
      <div class="video-section" id="webrtcVideoSection" style="display: none;">
        <h3>WebRTC Video (Loopback Peer Connection)</h3>
        <video id="webrtcVideo" autoplay playsinline muted></video>
      </div>
      </div>
    </div>
  </div>

  <script>
    class WebGPUVideoProcessor {
      constructor() {
        this.device = null;
        this.trackProcessor = null;
        this.trackGenerator = null;
        this.reader = null;
        this.writer = null;
        this.inputStream = null;
        this.outputStream = null;
        this.isProcessing = false;
        this.enableReadback = false;
        this.useWebGL2 = false;
        this.enableEncoding = false;
        this.enableDecoding = false;
        this.enableWebRTC = false;
        this.forceNextKeyframe = false;
        
        // Performance tracking
        this.frameCount = 0;
        this.readbackCount = 0;
        this.encodingFrameCount = 0;
        this.decodingFrameCount = 0;
        this.webrtcFrameCount = 0;
        this.lastFpsTime = performance.now();
        this.lastReadbackTime = performance.now();
        this.lastEncodingFpsTime = performance.now();
        this.lastDecodingFpsTime = performance.now();
        this.lastWebRTCFpsTime = performance.now();
        
        // WebGPU resources
        this.inputTexture = null;
        this.scaledTexture = null;
        this.outputBuffer = null;
        this.stagingBuffer = null;
        this.scalingComputePipeline = null;
        this.scalingBindGroupLayout = null;
        this.parametersBuffer = null;
        
        // WebGL2 resources
        this.gl = null;
        this.outputCanvas = null;
        this.scalingProgram = null;
        this.inputTexture2D = null;
        this.scaledTexture2D = null;
        this.framebuffer = null;
        this.readbackPixels = null;
        
        // Encoding components
        this.encodingTrackProcessor = null;
        this.encodingReader = null;
        this.encoder = null;
        
        // Decoding components
        this.decoder = null;
        this.decodedTrackGenerator = null;
        this.decodedWriter = null;
        this.decodedStream = null;
        
        // WebRTC components
        this.senderPC = null;
        this.receiverPC = null;
        this.webrtcStream = null;
        this.webrtcStatsInterval = null;
        this.lastWebRTCFramesDecoded = 0;
        
        // DOM elements
        this.startBtn = document.getElementById('startBtn');
        this.stopBtn = document.getElementById('stopBtn');
        this.enableReadbackCheckbox = document.getElementById('enableReadback');
        this.enableEncodingCheckbox = document.getElementById('enableEncoding');
        this.enableDecodingCheckbox = document.getElementById('enableDecoding');
        this.enableWebRTCCheckbox = document.getElementById('enableWebRTC');
        this.useWebGL2Checkbox = document.getElementById('useWebGL2');
        this.showInputVideoCheckbox = document.getElementById('showInputVideo');
        this.statusDiv = document.getElementById('status');
        this.inputVideo = document.getElementById('inputVideo');
        this.outputVideo = document.getElementById('outputVideo');
        this.decodedVideo = document.getElementById('decodedVideo');
        this.webrtcVideo = document.getElementById('webrtcVideo');
        this.inputVideoSection = document.getElementById('inputVideoSection');
        this.decodedVideoSection = document.getElementById('decodedVideoSection');
        this.webrtcVideoSection = document.getElementById('webrtcVideoSection');
        this.processingFpsSpan = document.getElementById('processingFps');
        this.readbackFpsSpan = document.getElementById('readbackFps');
        this.encodingFpsSpan = document.getElementById('encodingFps');
        this.decodingFpsSpan = document.getElementById('decodingFps');
        this.webrtcFpsSpan = document.getElementById('webrtcFps');
        this.inputResolutionSpan = document.getElementById('inputResolution');
        this.outputResolutionSpan = document.getElementById('outputResolution');
        this.gpuBackendSpan = document.getElementById('gpuBackend');
        this.encodingQueueSpan = document.getElementById('encodingQueue');
        this.decodingQueueSpan = document.getElementById('decodingQueue');
        
        this.bindEvents();
      }
      
      bindEvents() {
        this.startBtn.addEventListener('click', () => this.start());
        this.stopBtn.addEventListener('click', () => this.stop());
        this.enableReadbackCheckbox.addEventListener('change', (e) => {
          this.enableReadback = e.target.checked;
        });
        this.enableEncodingCheckbox.addEventListener('change', (e) => {
          this.enableEncoding = e.target.checked;
          
          // If WebCodecs encoding is enabled, disable WebRTC
          if (this.enableEncoding) {
            this.enableWebRTCCheckbox.checked = false;
            this.enableWebRTC = false;
            this.webrtcVideoSection.style.display = 'none';
          }
          
          // If encoding is enabled during runtime, initialize it
          if (this.enableEncoding && this.isProcessing && this.outputStream) {
            setTimeout(() => {
              this.initializeEncoding();
            }, 100);
          }
        });
        this.enableDecodingCheckbox.addEventListener('change', (e) => {
          this.enableDecoding = e.target.checked;
          this.decodedVideoSection.style.display = e.target.checked ? 'block' : 'none';
          
          // If WebCodecs decoding is enabled, disable WebRTC
          if (this.enableDecoding) {
            this.enableWebRTCCheckbox.checked = false;
            this.enableWebRTC = false;
            this.webrtcVideoSection.style.display = 'none';
          }
          
          // If decoding is enabled during runtime, initialize it
          if (this.enableDecoding && this.isProcessing) {
            this.initializeDecoding();
            // Force a keyframe from the encoder since decoder needs to start with one
            if (this.encoder) {
              this.encoder.flush().then(() => {
                // Request a keyframe on the next encode
                this.forceNextKeyframe = true;
              }).catch(console.warn);
            }
          }
        });
        this.enableWebRTCCheckbox.addEventListener('change', (e) => {
          this.enableWebRTC = e.target.checked;
          this.webrtcVideoSection.style.display = e.target.checked ? 'block' : 'none';
          
          // If WebRTC is enabled, disable WebCodecs options
          if (this.enableWebRTC) {
            this.enableEncodingCheckbox.checked = false;
            this.enableDecodingCheckbox.checked = false;
            this.enableEncoding = false;
            this.enableDecoding = false;
            this.decodedVideoSection.style.display = 'none';
          }
          
          // If WebRTC is enabled during runtime, initialize it
          if (this.enableWebRTC && this.isProcessing && this.outputStream) {
            setTimeout(() => {
              this.initializeWebRTC();
            }, 100);
          }
        });
        this.useWebGL2Checkbox.addEventListener('change', (e) => {
          this.useWebGL2 = e.target.checked;
          this.updateGpuBackendDisplay();
        });
        this.showInputVideoCheckbox.addEventListener('change', (e) => {
          this.inputVideoSection.style.display = e.target.checked ? 'block' : 'none';
        });
      }
      
      updateGpuBackendDisplay() {
        this.gpuBackendSpan.textContent = this.useWebGL2 ? 'WebGL2' : 'WebGPU';
      }
      
      updateStatus(message, type = 'info') {
        this.statusDiv.textContent = message;
        this.statusDiv.className = `status ${type}`;
      }
      
      updateStats() {
        const now = performance.now();
        const deltaTime = now - this.lastFpsTime;
        
        if (deltaTime >= 1000) {
          const processingFps = (this.frameCount * 1000 / deltaTime).toFixed(1);
          this.processingFpsSpan.textContent = processingFps;
          this.frameCount = 0;
          this.lastFpsTime = now;
        }
        
        const readbackDelta = now - this.lastReadbackTime;
        if (readbackDelta >= 1000) {
          const readbackFps = (this.readbackCount * 1000 / readbackDelta).toFixed(1);
          this.readbackFpsSpan.textContent = this.enableReadback ? readbackFps : '--';
          this.readbackCount = 0;
          this.lastReadbackTime = now;
        }
        
        const encodingDelta = now - this.lastEncodingFpsTime;
        if (encodingDelta >= 1000) {
          const encodingFps = (this.encodingFrameCount * 1000 / encodingDelta).toFixed(1);
          this.encodingFpsSpan.textContent = this.enableEncoding ? encodingFps : '--';
          this.encodingFrameCount = 0;
          this.lastEncodingFpsTime = now;
        }
        
        const decodingDelta = now - this.lastDecodingFpsTime;
        if (decodingDelta >= 1000) {
          const decodingFps = (this.decodingFrameCount * 1000 / decodingDelta).toFixed(1);
          this.decodingFpsSpan.textContent = this.enableDecoding ? decodingFps : '--';
          this.decodingFrameCount = 0;
          this.lastDecodingFpsTime = now;
        }
        
        const webrtcDelta = now - this.lastWebRTCFpsTime;
        if (webrtcDelta >= 1000) {
          // WebRTC FPS is now calculated from actual decoded frames stats
          // webrtcFrameCount contains the actual FPS from WebRTC stats
          const webrtcFps = this.enableWebRTC ? this.webrtcFrameCount.toFixed(1) : '--';
          this.webrtcFpsSpan.textContent = webrtcFps;
          // Reset for next measurement (stats monitoring updates this every second)
          this.lastWebRTCFpsTime = now;
        }
        
        // Update encoding queue size
        if (this.encoder) {
          this.encodingQueueSpan.textContent = this.encoder.encodeQueueSize;
        } else {
          this.encodingQueueSpan.textContent = '--';
        }
        
        // Update decoding queue size
        if (this.decoder) {
          this.decodingQueueSpan.textContent = this.decoder.decodeQueueSize;
        } else {
          this.decodingQueueSpan.textContent = '--';
        }
      }
      
      async initializeWebGPU() {
        try {
          if (!navigator.gpu) {
            throw new Error('WebGPU not supported in this browser');
          }
          
          const adapter = await navigator.gpu.requestAdapter();
          if (!adapter) {
            throw new Error('WebGPU adapter not available');
          }
          
          this.device = await adapter.requestDevice();
          
          // Create scaling compute pipeline for readback
          this.createScalingComputePipeline();
          
          return true;
        } catch (error) {
          this.updateStatus(`WebGPU initialization failed: ${error.message}`, 'error');
          return false;
        }
      }
      
      initializeWebGL2() {
        try {
          // Create offscreen canvases for WebGL2 processing (no DOM overhead)
          this.outputCanvas = new OffscreenCanvas(1, 1); // Will be resized dynamically
          
          this.gl = this.outputCanvas.getContext('webgl2');
          if (!this.gl) {
            throw new Error('WebGL2 not supported in this browser');
          }
          
          // Create scaling shader program
          this.createWebGL2ScalingProgram();
          
          // Initialize WebGL2 resources
          this.initializeWebGL2Resources();
          
          return true;
        } catch (error) {
          this.updateStatus(`WebGL2 initialization failed: ${error.message}`, 'error');
          return false;
        }
      }
      
      createWebGL2ScalingProgram() {
        const vertexShaderSource = `#version 300 es
          in vec2 a_position;
          in vec2 a_texCoord;
          out vec2 v_texCoord;
          
          void main() {
            gl_Position = vec4(a_position, 0.0, 1.0);
            v_texCoord = a_texCoord;
          }
        `;
        
        const fragmentShaderSource = `#version 300 es
          precision mediump float;
          
          uniform sampler2D u_texture;
          in vec2 v_texCoord;
          out vec4 fragColor;
          
          void main() {
            fragColor = texture(u_texture, v_texCoord);
          }
        `;
        
        const vertexShader = this.createShader(this.gl.VERTEX_SHADER, vertexShaderSource);
        const fragmentShader = this.createShader(this.gl.FRAGMENT_SHADER, fragmentShaderSource);
        
        this.scalingProgram = this.gl.createProgram();
        this.gl.attachShader(this.scalingProgram, vertexShader);
        this.gl.attachShader(this.scalingProgram, fragmentShader);
        this.gl.linkProgram(this.scalingProgram);
        
        if (!this.gl.getProgramParameter(this.scalingProgram, this.gl.LINK_STATUS)) {
          throw new Error('WebGL2 program linking failed: ' + this.gl.getProgramInfoLog(this.scalingProgram));
        }
      }
      
      createShader(type, source) {
        const shader = this.gl.createShader(type);
        this.gl.shaderSource(shader, source);
        this.gl.compileShader(shader);
        
        if (!this.gl.getShaderParameter(shader, this.gl.COMPILE_STATUS)) {
          const error = this.gl.getShaderInfoLog(shader);
          this.gl.deleteShader(shader);
          throw new Error('WebGL2 shader compilation failed: ' + error);
        }
        
        return shader;
      }
      
      initializeWebGL2Resources() {
        // Create vertex buffer for fullscreen quad
        const positions = new Float32Array([
          -1, -1,  0, 1,
           1, -1,  1, 1,
          -1,  1,  0, 0,
           1,  1,  1, 0,
        ]);
        
        const positionBuffer = this.gl.createBuffer();
        this.gl.bindBuffer(this.gl.ARRAY_BUFFER, positionBuffer);
        this.gl.bufferData(this.gl.ARRAY_BUFFER, positions, this.gl.STATIC_DRAW);
        
        // Create VAO
        this.vao = this.gl.createVertexArray();
        this.gl.bindVertexArray(this.vao);
        
        // Set up attributes
        const positionLocation = this.gl.getAttribLocation(this.scalingProgram, 'a_position');
        const texCoordLocation = this.gl.getAttribLocation(this.scalingProgram, 'a_texCoord');
        
        this.gl.enableVertexAttribArray(positionLocation);
        this.gl.vertexAttribPointer(positionLocation, 2, this.gl.FLOAT, false, 16, 0);
        
        this.gl.enableVertexAttribArray(texCoordLocation);
        this.gl.vertexAttribPointer(texCoordLocation, 2, this.gl.FLOAT, false, 16, 8);
        
        // Create textures
        this.inputTexture2D = this.gl.createTexture();
        this.scaledTexture2D = this.gl.createTexture();
        
        // Create framebuffer for scaled rendering
        this.framebuffer = this.gl.createFramebuffer();
        
        // Initialize readback pixel array
        this.readbackPixels = new Uint8Array(255 * 144 * 4);
      }
      
      async initializeCamera() {
        try {
          this.inputStream = await navigator.mediaDevices.getUserMedia({
            video: { 
              width: { exact: 1280 }, 
              height: { exact: 720 }, 
              frameRate: { exact: 30 }
            }
          });
          
          this.inputVideo.srcObject = this.inputStream;
          await new Promise(resolve => this.inputVideo.onloadedmetadata = resolve);
          
          // Update resolution display
          this.inputResolutionSpan.textContent = `${this.inputVideo.videoWidth}Ã—${this.inputVideo.videoHeight}`;
          this.outputResolutionSpan.textContent = `${this.inputVideo.videoWidth}Ã—${this.inputVideo.videoHeight}`;
          
          return true;
        } catch (error) {
          this.updateStatus(`Camera access failed: ${error.message}`, 'error');
          return false;
        }
      }
      
      createScalingComputePipeline() {
        // Create compute shader for scaling down textures
        const computeShader = this.device.createShaderModule({
          code: `
            struct Parameters {
              output_size : vec2<u32>,
            };

            @group(0) @binding(0) var input : texture_2d<f32>;
            @group(0) @binding(1) var output : texture_storage_2d<rgba8unorm, write>;
            @group(0) @binding(2) var<uniform> params : Parameters;
            @group(0) @binding(3) var linear_sampler : sampler;

            @compute @workgroup_size(8, 8)
            fn main(@builtin(global_invocation_id) gid : vec3<u32>) {
              if (gid.x >= params.output_size.x || gid.y >= params.output_size.y) {
                return;
              }
              // Map output pixel to input texture coordinates [0,1]
              let output_coord = vec2<f32>(gid.xy) + vec2<f32>(0.5, 0.5);
              let input_coord = output_coord / vec2<f32>(params.output_size);
              let input_value = textureSampleLevel(input, linear_sampler, input_coord, 0);
              textureStore(output, vec2<i32>(gid.xy), input_value);
            }
          `
        });
        
        // Create bind group layout
        this.scalingBindGroupLayout = this.device.createBindGroupLayout({
          entries: [
            {
              binding: 0,
              visibility: GPUShaderStage.COMPUTE,
              texture: {
                sampleType: 'float',
                viewDimension: '2d',
              },
            },
            {
              binding: 1,
              visibility: GPUShaderStage.COMPUTE,
              storageTexture: {
                access: 'write-only',
                format: 'rgba8unorm',
                viewDimension: '2d',
              },
            },
            {
              binding: 2,
              visibility: GPUShaderStage.COMPUTE,
              buffer: {
                type: 'uniform',
              },
            },
            {
              binding: 3,
              visibility: GPUShaderStage.COMPUTE,
              sampler: {},
            },
          ],
        });
        
        // Create compute pipeline
        this.scalingComputePipeline = this.device.createComputePipeline({
          layout: this.device.createPipelineLayout({
            bindGroupLayouts: [this.scalingBindGroupLayout],
          }),
          compute: {
            module: computeShader,
            entryPoint: 'main',
          },
        });
        
        // Create parameters buffer
        this.parametersBuffer = this.device.createBuffer({
          size: 8, // vec2<u32> = 8 bytes
          usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
        });
      }
      
      initializeMediaStreamProcessing() {
        try {
          const videoTrack = this.inputStream.getVideoTracks()[0];
          if (!videoTrack) {
            throw new Error('No video track found');
          }
          
          // Create MediaStreamTrackProcessor for input
          this.trackProcessor = new MediaStreamTrackProcessor({ track: videoTrack });
          this.reader = this.trackProcessor.readable.getReader();
          
          // Create MediaStreamTrackGenerator for output
          this.trackGenerator = new MediaStreamTrackGenerator({ kind: 'video' });
          this.writer = this.trackGenerator.writable.getWriter();
          this.outputStream = new MediaStream([this.trackGenerator]);
          
          // Set output video source
          this.outputVideo.srcObject = this.outputStream;
          
          return true;
        } catch (error) {
          this.updateStatus(`MediaStream processing setup failed: ${error.message}`, 'error');
          return false;
        }
      }
      
      initializeEncoding() {
        if (!this.enableEncoding || !this.outputStream) {
          return true;
        }
        
        try {
          // Create MediaStreamTrackProcessor for encoding from the WebGPU/WebGL2 output stream
          const videoTrack = this.outputStream.getVideoTracks()[0];
          if (!videoTrack) {
            console.error('No output video track found for encoding');
            throw new Error('No output video track found for encoding');
          }
          
          console.log('Setting up encoding with video track:', videoTrack);
          
          this.encodingTrackProcessor = new MediaStreamTrackProcessor({ track: videoTrack });
          this.encodingReader = this.encodingTrackProcessor.readable.getReader();
          
          // Initialize H.264 encoder
          this.initializeH264Encoder();
          
          // Start encoding loop
          this.processEncodingFrame();
          
          // Force the first frame to be a keyframe
          this.forceNextKeyframe = true;
          
          // Initialize decoding if enabled
          if (this.enableDecoding) {
            this.initializeDecoding();
          }
          
          return true;
        } catch (error) {
          console.error('Encoding setup failed:', error);
          this.updateStatus(`Encoding setup failed: ${error.message}`, 'error');
          return false;
        }
      }
      
      initializeH264Encoder() {
        const config = {
          codec: 'avc1.42E01F', // H.264 Baseline Profile, Level 3.1
          width: 1280,
          height: 720,
          bitrate: 2000000, // 2 Mbps
          framerate: 30,
          bitrateMode: 'constant',
          //hardwareAcceleration: 'prefer-hardware',
          avc: { format: 'annexb' }
        };
        
        this.encoder = new VideoEncoder({
          output: (chunk, metadata) => {
            // If decoding is enabled, pass the chunk directly to the decoder
            if (this.enableDecoding && this.decoder) {
              try {
                this.decoder.decode(chunk);
              } catch (error) {
                console.error('Decoding error:', error);
              }
            }
            // Here you could also save the chunk to a file or stream it
          },
          error: (error) => {
            console.error('H.264 encoding error:', error);
          }
        });
        
        this.encoder.configure(config);
      }
      
      async processEncodingFrame() {
        if (!this.isProcessing || !this.enableEncoding || !this.encodingReader) {
          return;
        }
        
        try {
          const readResult = await this.encodingReader.read();
          if (readResult.done) {
            return;
          }
          
          if (!readResult.value) {
            setTimeout(() => this.processEncodingFrame(), 16);
            return;
          }
          
          const videoFrame = readResult.value;
          
          // Ensure proper timestamp and duration
          const timestamp = videoFrame.timestamp || (performance.now() * 1000);
          const duration = videoFrame.duration || (1000000 / 30); // 30fps default
          
          // Create a new VideoFrame with proper timing
          const frameForEncoding = new VideoFrame(videoFrame, {
            timestamp: timestamp,
            duration: duration
          });
          
          // Encode frame (only if queue is not too full)
          if (this.encoder.encodeQueueSize < 5) {
            // Check if we need to force a keyframe
            const keyFrame = this.forceNextKeyframe;
            if (this.forceNextKeyframe) {
              this.forceNextKeyframe = false; // Reset the flag
            }
            
            this.encoder.encode(frameForEncoding, { keyFrame });
            this.encodingFrameCount++;
          } else {
            console.warn('H.264 encoder queue full, dropping frame');
          }
          
          // Clean up
          videoFrame.close();
          frameForEncoding.close();
          
          // Continue processing
          this.processEncodingFrame();
          
        } catch (error) {
          console.error('Error in H.264 encoding loop:', error);
          if (this.isProcessing) {
            setTimeout(() => this.processEncodingFrame(), 100);
          }
        }
      }
      
      initializeDecoding() {
        if (!this.enableDecoding) {
          return true;
        }
        
        try {
          // Create MediaStreamTrackGenerator for decoded video output
          this.decodedTrackGenerator = new MediaStreamTrackGenerator({ kind: 'video' });
          this.decodedWriter = this.decodedTrackGenerator.writable.getWriter();
          this.decodedStream = new MediaStream([this.decodedTrackGenerator]);
          
          // Set decoded video source
          this.decodedVideo.srcObject = this.decodedStream;
          
          // Initialize H.264 decoder
          this.initializeH264Decoder();
          
          return true;
        } catch (error) {
          console.error('Decoding setup failed:', error);
          this.updateStatus(`Decoding setup failed: ${error.message}`, 'error');
          return false;
        }
      }
      
      initializeH264Decoder() {
        const config = {
          codec: 'avc1.42E01F', // H.264 Baseline Profile, Level 3.1
        };
        
        this.decoder = new VideoDecoder({
          output: async (videoFrame) => {
            try {
              // Write decoded frame to MediaStreamTrackGenerator
              if (this.decodedWriter && this.enableDecoding) {
                await this.decodedWriter.write(videoFrame);
                this.decodingFrameCount++;
              }
              videoFrame.close();
            } catch (error) {
              console.warn('Decoded frame write failed:', error);
              videoFrame.close();
            }
          },
          error: (error) => {
            console.error('H.264 decoding error:', error);
          }
        });
        
        this.decoder.configure(config);
      }
      
      async initializeWebRTC() {
        if (!this.enableWebRTC || !this.outputStream) {
          return true;
        }
        
        try {
          // Create sender peer connection
          this.senderPC = new RTCPeerConnection({
            iceServers: [] // No STUN/TURN needed for loopback
          });
          
          // Create receiver peer connection  
          this.receiverPC = new RTCPeerConnection({
            iceServers: [] // No STUN/TURN needed for loopback
          });
          
          // Add the output stream to sender
          const videoTrack = this.outputStream.getVideoTracks()[0];
          if (!videoTrack) {
            throw new Error('No output video track found for WebRTC');
          }
          
          this.senderPC.addTrack(videoTrack, this.outputStream);
          
          // Configure H.264 codec preference
          const transceivers = this.senderPC.getTransceivers();
          if (transceivers.length > 0) {
            const sender = transceivers[0].sender;
            const params = sender.getParameters();
            
            // Set H.264 codec preferences
            if (params.codecs) {
              // Filter and prioritize H.264 codecs
              const h264Codecs = params.codecs.filter(codec => 
                codec.mimeType.toLowerCase().includes('h264') || 
                codec.mimeType.toLowerCase().includes('avc')
              );
              
              if (h264Codecs.length > 0) {
                params.codecs = h264Codecs;
                await sender.setParameters(params);
                console.log('H.264 codec forced for WebRTC sender');
              }
            }
          }
          
          // Handle incoming stream on receiver
          this.receiverPC.ontrack = (event) => {
            console.log('WebRTC received track:', event.track);
            this.webrtcStream = new MediaStream([event.track]);
            
            // Set WebRTC video source
            this.webrtcVideo.srcObject = this.webrtcStream;
            this.webrtcVideoSection.style.display = 'block';
            
            // Start WebRTC stats monitoring
            this.startWebRTCStatsMonitoring();
          };
          
          // Handle ICE candidates (for loopback, these should be local)
          this.senderPC.onicecandidate = (event) => {
            if (event.candidate) {
              this.receiverPC.addIceCandidate(event.candidate).catch(console.warn);
            }
          };
          
          this.receiverPC.onicecandidate = (event) => {
            if (event.candidate) {
              this.senderPC.addIceCandidate(event.candidate).catch(console.warn);
            }
          };
          
          // Create offer/answer exchange with H.264 codec preference
          const offer = await this.senderPC.createOffer();
          
          // Modify SDP to prioritize H.264
          offer.sdp = this.prioritizeH264InSDP(offer.sdp);
          
          await this.senderPC.setLocalDescription(offer);
          
          await this.receiverPC.setRemoteDescription(offer);
          const answer = await this.receiverPC.createAnswer();
          
          // Modify answer SDP to prioritize H.264
          answer.sdp = this.prioritizeH264InSDP(answer.sdp);
          
          await this.receiverPC.setLocalDescription(answer);
          
          await this.senderPC.setRemoteDescription(answer);
          
          console.log('WebRTC loopback connection established');
          
          return true;
        } catch (error) {
          console.error('WebRTC setup failed:', error);
          this.updateStatus(`WebRTC setup failed: ${error.message}`, 'error');
          return false;
        }
      }
      
      prioritizeH264InSDP(sdp) {
        // Split SDP into lines
        const lines = sdp.split('\r\n');
        let mLineIndex = -1;
        
        // Find the video media line
        for (let i = 0; i < lines.length; i++) {
          if (lines[i].startsWith('m=video')) {
            mLineIndex = i;
            break;
          }
        }
        
        if (mLineIndex === -1) {
          return sdp; // No video line found
        }
        
        // Extract payload types from m-line
        const mLine = lines[mLineIndex];
        const payloadTypes = mLine.split(' ').slice(3);
        
        // Find H.264 payload types
        const h264PayloadTypes = [];
        const otherPayloadTypes = [];
        
        for (const pt of payloadTypes) {
          // Look for corresponding rtpmap line
          const rtpmapLine = lines.find(line => 
            line.startsWith(`a=rtpmap:${pt}`) && 
            (line.toLowerCase().includes('h264') || line.toLowerCase().includes('avc'))
          );
          
          if (rtpmapLine) {
            h264PayloadTypes.push(pt);
          } else {
            otherPayloadTypes.push(pt);
          }
        }
        
        // If we found H.264 codecs, prioritize them
        if (h264PayloadTypes.length > 0) {
          const newPayloadTypes = [...h264PayloadTypes, ...otherPayloadTypes];
          const mLineParts = mLine.split(' ');
          lines[mLineIndex] = `${mLineParts.slice(0, 3).join(' ')} ${newPayloadTypes.join(' ')}`;
          
          console.log('H.264 codecs prioritized in SDP:', h264PayloadTypes);
        }
        
        return lines.join('\r\n');
      }
      
      startWebRTCStatsMonitoring() {
        if (this.webrtcStatsInterval) {
          clearInterval(this.webrtcStatsInterval);
        }
        
        this.webrtcStatsInterval = setInterval(async () => {
          if (!this.receiverPC || !this.enableWebRTC || !this.isProcessing) {
            return;
          }
          
          try {
            const stats = await this.receiverPC.getStats();
            
            // Look for inbound video stream stats
            for (const [id, stat] of stats) {
              if (stat.type === 'inbound-rtp' && stat.mediaType === 'video') {
                const framesDecoded = stat.framesDecoded || 0;
                
                // Calculate FPS based on frames decoded
                if (this.lastWebRTCFramesDecoded > 0) {
                  const framesDelta = framesDecoded - this.lastWebRTCFramesDecoded;
                  // Stats are collected every second, so framesDelta is already FPS
                  this.webrtcFrameCount = framesDelta;
                }
                
                this.lastWebRTCFramesDecoded = framesDecoded;
                
                // Log additional useful stats
                if (stat.framesDropped > 0) {
                  console.warn(`WebRTC frames dropped: ${stat.framesDropped}`);
                }
                
                break; // Found the video inbound stream
              }
            }
          } catch (error) {
            console.warn('Failed to get WebRTC stats:', error);
          }
        }, 1000); // Check stats every second
      }
      
      createGPUBuffers(width, height) {
        // Clean up existing buffers and textures
        if (this.outputBuffer) this.outputBuffer.destroy();
        if (this.stagingBuffer) this.stagingBuffer.destroy();
        if (this.scaledTexture) this.scaledTexture.destroy();
        
        // Create scaled texture (255x144)
        const scaledWidth = 255;
        const scaledHeight = 144;
        
        this.scaledTexture = this.device.createTexture({
          size: [scaledWidth, scaledHeight, 1],
          format: 'rgba8unorm',
          usage: GPUTextureUsage.STORAGE_BINDING | 
                 GPUTextureUsage.COPY_SRC |
                 GPUTextureUsage.TEXTURE_BINDING,
        });
        
        const bytesPerPixel = 4; // RGBA
        const bytesPerRow = scaledWidth * bytesPerPixel;
        const bytesPerRowAligned = Math.ceil(bytesPerRow / 256) * 256; // Align to 256 bytes
        const bufferSize = bytesPerRowAligned * scaledHeight;
        
        // Buffer for reading back texture data (with proper alignment)
        this.outputBuffer = this.device.createBuffer({
          size: bufferSize,
          usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ,
        });
        
        // Staging buffer for efficient readback
        this.stagingBuffer = this.device.createBuffer({
          size: bufferSize,
          usage: GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST,
        });
      }
      
      async processVideoFrame() {
        if (!this.isProcessing) return;
        
        try {
          // Read VideoFrame from MediaStreamTrackProcessor
          const readResult = await this.reader.read();
          if (readResult.done) {
            // Stream ended, stop processing
            return;
          }
          
          if (!readResult.value) {
            // No frame available, continue processing but with a small delay
            setTimeout(() => this.processVideoFrame(), 16); // ~60fps check rate
            return;
          }
          
          const videoFrame = readResult.value;
          const width = videoFrame.displayWidth;
          const height = videoFrame.displayHeight;
          
          let outputVideoFrame;
          
          if (this.useWebGL2) {
            // Process with WebGL2
            outputVideoFrame = await this.processWithWebGL2(videoFrame, width, height);
          } else {
            // Process with WebGPU
            outputVideoFrame = await this.processWithWebGPU(videoFrame, width, height);
          }
          
          // Write processed frame to MediaStreamTrackGenerator
          if (outputVideoFrame) {
            await this.writer.write(outputVideoFrame);
            outputVideoFrame.close();
          }
          
          // Clean up
          videoFrame.close();
          
          // Update statistics
          this.frameCount++;
          this.updateStats();
          
          // Continue processing immediately to handle the next frame
          this.processVideoFrame();
          
        } catch (error) {
          console.error('Error processing video frame:', error);
          if (this.isProcessing) {
            // Continue processing even if there's an error, but with a delay
            setTimeout(() => this.processVideoFrame(), 100);
          }
        }
      }
      
      async processWithWebGPU(videoFrame, width, height) {
        // Create or recreate input texture if size changed
        if (!this.inputTexture || 
            this.inputTexture.width !== width || 
            this.inputTexture.height !== height) {
          
          if (this.inputTexture) this.inputTexture.destroy();
          
          this.inputTexture = this.device.createTexture({
            size: [width, height, 1],
            format: 'rgba8unorm',
            usage: GPUTextureUsage.TEXTURE_BINDING | 
                   GPUTextureUsage.COPY_DST | 
                   GPUTextureUsage.COPY_SRC |
                   GPUTextureUsage.RENDER_ATTACHMENT,
          });
        }
        
        // Upload VideoFrame to GPU texture using copyExternalImageToTexture
        this.device.queue.copyExternalImageToTexture(
          { source: videoFrame },
          { texture: this.inputTexture },
          [width, height, 1]
        );
        
        // Optional: Perform readback
        if (this.enableReadback) {
          // Always recreate buffers for readback to ensure they're fresh
          this.createGPUBuffers(width, height);
          await this.performWebGPUReadback(width, height);
        }
        
        // Create output VideoFrame from the same GPU texture
        return new VideoFrame(videoFrame, {
          timestamp: videoFrame.timestamp,
          duration: videoFrame.duration
        });
      }
      
      async processWithWebGL2(videoFrame, width, height) {
        // Set canvas size
        this.outputCanvas.width = width;
        this.outputCanvas.height = height;
        
        // Upload to WebGL2 texture using texImage2D
        this.gl.bindTexture(this.gl.TEXTURE_2D, this.inputTexture2D);
        this.gl.texImage2D(
          this.gl.TEXTURE_2D, 0, this.gl.RGBA, 
          this.gl.RGBA, this.gl.UNSIGNED_BYTE, videoFrame
        );
        this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MIN_FILTER, this.gl.LINEAR);
        this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MAG_FILTER, this.gl.LINEAR);
        this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_S, this.gl.CLAMP_TO_EDGE);
        this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_T, this.gl.CLAMP_TO_EDGE);
        
        // Optional: Perform readback and scale-down
        if (this.enableReadback) {
          await this.performWebGL2Readback(width, height);
        }
        
        // Render back to output canvas for display
        this.gl.viewport(0, 0, width, height);
        this.gl.bindFramebuffer(this.gl.FRAMEBUFFER, null);
        this.gl.useProgram(this.scalingProgram);
        this.gl.bindVertexArray(this.vao);
        this.gl.bindTexture(this.gl.TEXTURE_2D, this.inputTexture2D);
        this.gl.drawArrays(this.gl.TRIANGLE_STRIP, 0, 4);
        
        // Create output VideoFrame from canvas
        return new VideoFrame(this.outputCanvas, {
          timestamp: videoFrame.timestamp,
          duration: videoFrame.duration
        });
      }
      
      async performWebGL2Readback(width, height) {
        try {
          const scaledWidth = 255;
          const scaledHeight = 144;
          
          // Set up scaled texture
          this.gl.bindTexture(this.gl.TEXTURE_2D, this.scaledTexture2D);
          this.gl.texImage2D(
            this.gl.TEXTURE_2D, 0, this.gl.RGBA,
            scaledWidth, scaledHeight, 0,
            this.gl.RGBA, this.gl.UNSIGNED_BYTE, null
          );
          this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MIN_FILTER, this.gl.LINEAR);
          this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MAG_FILTER, this.gl.LINEAR);
          this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_S, this.gl.CLAMP_TO_EDGE);
          this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_T, this.gl.CLAMP_TO_EDGE);
          
          // Set up framebuffer for scaled rendering
          this.gl.bindFramebuffer(this.gl.FRAMEBUFFER, this.framebuffer);
          this.gl.framebufferTexture2D(
            this.gl.FRAMEBUFFER, this.gl.COLOR_ATTACHMENT0,
            this.gl.TEXTURE_2D, this.scaledTexture2D, 0
          );
          
          // Render scaled-down version
          this.gl.viewport(0, 0, scaledWidth, scaledHeight);
          this.gl.useProgram(this.scalingProgram);
          this.gl.bindVertexArray(this.vao);
          this.gl.bindTexture(this.gl.TEXTURE_2D, this.inputTexture2D);
          this.gl.drawArrays(this.gl.TRIANGLE_STRIP, 0, 4);
          
          // Read back pixels
          this.gl.readPixels(
            0, 0, scaledWidth, scaledHeight,
            this.gl.RGBA, this.gl.UNSIGNED_BYTE, this.readbackPixels
          );
          
          this.readbackCount++;
          
        } catch (error) {
          console.warn('WebGL2 readback failed:', error);
        }
      }
      
      async performWebGPUReadback(width, height) {
        try {
          const commandEncoder = this.device.createCommandEncoder();
          
          // Scale down the input texture to 255x144 using compute pipeline
          const scaledWidth = 255;
          const scaledHeight = 144;

          // Update parameters buffer with output size only
          const parametersData = new ArrayBuffer(8);
          const parametersView = new DataView(parametersData);
          parametersView.setUint32(0, scaledWidth, true);  // output_size.x
          parametersView.setUint32(4, scaledHeight, true); // output_size.y
          
          this.device.queue.writeBuffer(this.parametersBuffer, 0, parametersData);

          // Create sampler for texture sampling
          const sampler = this.device.createSampler({
            magFilter: 'linear',
            minFilter: 'linear',
          });
          
          // Create bind group for compute operation
          const bindGroup = this.device.createBindGroup({
            layout: this.scalingBindGroupLayout,
            entries: [
              {
                binding: 0,
                resource: this.inputTexture.createView(),
              },
              {
                binding: 1,
                resource: this.scaledTexture.createView(),
              },
              {
                binding: 2,
                resource: { buffer: this.parametersBuffer },
              },
              {
                binding: 3,
                resource: sampler,
              },
            ],
          });
          
          // Dispatch compute shader
          const computePass = commandEncoder.beginComputePass();
          computePass.setPipeline(this.scalingComputePipeline);
          computePass.setBindGroup(0, bindGroup);
          
          // Calculate dispatch size (workgroup size is 8x8)
          const dispatchX = Math.ceil(scaledWidth / 8);
          const dispatchY = Math.ceil(scaledHeight / 8);
          computePass.dispatchWorkgroups(dispatchX, dispatchY);
          computePass.end();
          
          // Copy scaled texture to buffer
          const bytesPerRow = scaledWidth * 4; // RGBA
          const bytesPerRowAligned = Math.ceil(bytesPerRow / 256) * 256; // Align to 256 bytes
          
          commandEncoder.copyTextureToBuffer(
            {
              texture: this.scaledTexture,
              origin: [0, 0, 0],
            },
            {
              buffer: this.outputBuffer,
              bytesPerRow: bytesPerRowAligned,
              rowsPerImage: scaledHeight,
            },
            [scaledWidth, scaledHeight, 1]
          );
          
          this.device.queue.submit([commandEncoder.finish()]);
          
          // Wait for GPU operations to complete
          await this.device.queue.onSubmittedWorkDone();
          
          // Map and read buffer data for readback
          await this.outputBuffer.mapAsync(GPUMapMode.READ);
          const arrayBuffer = this.outputBuffer.getMappedRange();
          this.outputBuffer.unmap();
          
          this.readbackCount++;
          
        } catch (error) {
          console.warn('Readback failed:', error);
        }
      }
      
      
      async start() {
        this.updateStatus('Initializing...', 'info');
        this.startBtn.disabled = true;
        
        // Initialize GPU backend
        let initSuccess = false;
        if (this.useWebGL2) {
          initSuccess = this.initializeWebGL2();
        } else {
          initSuccess = await this.initializeWebGPU();
        }
        
        if (!initSuccess) {
          this.startBtn.disabled = false;
          return;
        }
        
        // Initialize camera
        if (!await this.initializeCamera()) {
          this.startBtn.disabled = false;
          return;
        }
        
        // Initialize MediaStream processing
        if (!this.initializeMediaStreamProcessing()) {
          this.startBtn.disabled = false;
          return;
        }
        
        // Update GPU backend display
        this.updateGpuBackendDisplay();
        
        // Start processing
        this.isProcessing = true;
        this.updateStatus('Processing video...', 'success');
        this.stopBtn.disabled = false;
        
        // Start the processing loop
        this.processVideoFrame();
        
        // Initialize encoding after a short delay to ensure output stream is ready
        if (this.enableEncoding) {
          setTimeout(() => {
            this.initializeEncoding();
          }, 1000);
        }
        
        // Initialize decoding if enabled
        if (this.enableDecoding) {
          this.initializeDecoding();
        }
        
        // Initialize WebRTC if enabled
        if (this.enableWebRTC) {
          setTimeout(() => {
            this.initializeWebRTC();
          }, 1000);
        }
      }
      
      stop() {
        this.isProcessing = false;
        this.updateStatus('Stopping...', 'info');
        
        // Clean up MediaStream processing
        if (this.reader) {
          this.reader.cancel().catch(console.warn);
          this.reader = null;
        }
        
        if (this.writer) {
          this.writer.close().catch(console.warn);
          this.writer = null;
        }
        
        // Clean up encoding
        if (this.encodingReader) {
          this.encodingReader.cancel().catch(console.warn);
          this.encodingReader = null;
        }
        
        if (this.encoder) {
          this.encoder.flush().catch(console.warn);
          this.encoder.close();
          this.encoder = null;
        }
        
        // Clean up decoding
        if (this.decodedWriter) {
          this.decodedWriter.close().catch(console.warn);
          this.decodedWriter = null;
        }
        
        if (this.decoder) {
          this.decoder.flush().catch(console.warn);
          this.decoder.close();
          this.decoder = null;
        }
        
        // Clean up WebRTC
        if (this.webrtcStatsInterval) {
          clearInterval(this.webrtcStatsInterval);
          this.webrtcStatsInterval = null;
        }
        
        if (this.senderPC) {
          this.senderPC.close();
          this.senderPC = null;
        }
        
        if (this.receiverPC) {
          this.receiverPC.close();
          this.receiverPC = null;
        }
        
        if (this.webrtcStream) {
          this.webrtcStream.getTracks().forEach(track => track.stop());
          this.webrtcStream = null;
        }
        
        // Clean up encoded chunks
        // No longer needed since we're not storing chunks
        
        if (this.trackProcessor) {
          this.trackProcessor = null;
        }
        
        if (this.encodingTrackProcessor) {
          this.encodingTrackProcessor = null;
        }
        
        if (this.decodedTrackGenerator) {
          this.decodedTrackGenerator = null;
        }
        
        if (this.trackGenerator) {
          this.trackGenerator = null;
        }
        
        // Stop camera
        if (this.inputStream) {
          this.inputStream.getTracks().forEach(track => track.stop());
          this.inputStream = null;
        }
        
        // Clear video sources
        this.inputVideo.srcObject = null;
        this.outputVideo.srcObject = null;
        this.decodedVideo.srcObject = null;
        this.webrtcVideo.srcObject = null;
        this.outputStream = null;
        this.decodedStream = null;
        
        // Clean up GPU resources
        if (this.useWebGL2) {
          // Clean up WebGL2 resources
          if (this.gl) {
            if (this.inputTexture2D) this.gl.deleteTexture(this.inputTexture2D);
            if (this.scaledTexture2D) this.gl.deleteTexture(this.scaledTexture2D);
            if (this.framebuffer) this.gl.deleteFramebuffer(this.framebuffer);
            if (this.scalingProgram) this.gl.deleteProgram(this.scalingProgram);
            if (this.vao) this.gl.deleteVertexArray(this.vao);
          }
          this.gl = null;
          this.outputCanvas = null;
          this.inputTexture2D = null;
          this.scaledTexture2D = null;
          this.framebuffer = null;
          this.scalingProgram = null;
          this.readbackPixels = null;
        } else {
          // Clean up WebGPU resources
          if (this.inputTexture) {
            this.inputTexture.destroy();
            this.inputTexture = null;
          }
          
          if (this.scaledTexture) {
            this.scaledTexture.destroy();
            this.scaledTexture = null;
          }
          
          if (this.outputBuffer) {
            this.outputBuffer.destroy();
            this.outputBuffer = null;
          }
          
          if (this.stagingBuffer) {
            this.stagingBuffer.destroy();
            this.stagingBuffer = null;
          }
          
          if (this.parametersBuffer) {
            this.parametersBuffer.destroy();
            this.parametersBuffer = null;
          }
        }
        
        // Reset UI
        this.startBtn.disabled = false;
        this.stopBtn.disabled = true;
        this.updateStatus('Stopped', 'info');
        
        // Reset stats
        this.processingFpsSpan.textContent = '--';
        this.readbackFpsSpan.textContent = '--';
        this.encodingFpsSpan.textContent = '--';
        this.decodingFpsSpan.textContent = '--';
        this.webrtcFpsSpan.textContent = '--';
        this.inputResolutionSpan.textContent = '--';
        this.outputResolutionSpan.textContent = '--';
        this.gpuBackendSpan.textContent = '--';
        this.encodingQueueSpan.textContent = '--';
        this.decodingQueueSpan.textContent = '--';
        this.frameCount = 0;
        this.readbackCount = 0;
        this.encodingFrameCount = 0;
        this.decodingFrameCount = 0;
        this.webrtcFrameCount = 0;
        this.lastWebRTCFramesDecoded = 0;
      }
    }
    
    // Initialize the application
    const processor = new WebGPUVideoProcessor();
    
    // Check WebGPU support on page load
    if (!navigator.gpu) {
      document.getElementById('status').textContent = 'WebGPU is not supported in this browser (WebGL2 still available)';
      document.getElementById('status').className = 'status info';
      // Don't disable the start button - WebGL2 might still work
    }
  </script>
</body>

</html>
